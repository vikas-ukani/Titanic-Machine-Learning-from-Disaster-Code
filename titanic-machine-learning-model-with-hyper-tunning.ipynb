{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Packages and Models for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Linear Algebra\n",
    "\n",
    "import pandas as pd # Dataset related Filtering\n",
    "\n",
    "import seaborn as sns # Beautiful Graphs\n",
    "sns.set_style('dark') # Set graph styles to 'dark'\n",
    "\n",
    "import matplotlib.pyplot as plt # Normal ploating graphs\n",
    "# show graphs in this notebook only \n",
    "%matplotlib inline\n",
    "\n",
    "!pip install plotly\n",
    "import plotly.express as px # For interactive plots\n",
    "\n",
    "\n",
    "# ignore  the warning\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First of all We need to data to train our model to predict better result.\n",
    "\n",
    "So, We need the data for train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ###  Dataset Informations:\n",
    "\n",
    "1. survival - Survival (0 = No; 1 = Yes)\n",
    "- class - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "- name - Name\n",
    "- sex - Sex\n",
    "- age - Age\n",
    "- sibsp - Number of Siblings/Spouses Aboard\n",
    "- parch - Number of Parents/Children Aboard\n",
    "- ticket - Ticket Number\n",
    "- fare - Passenger Fare\n",
    "- cabin - Cabin\n",
    "- embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Train.csv File \n",
    "trainDF = pd.read_csv('./../input/titanic/train.csv')\n",
    "\n",
    "# show first five rows from training dataset\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Test.csv File \n",
    "testDF = pd.read_csv('./../input/titanic/test.csv')\n",
    "\n",
    "#  show 5 rows\n",
    "testDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 5 Rows\n",
    "testDF.head() # train() for last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_shape(train, test):\n",
    "    \"\"\" \n",
    "    display the shape of train and test DF \n",
    "    \n",
    "    \"\"\"   \n",
    "    print(\" Shape of Training DF\", train.shape)\n",
    "    print(\"\")\n",
    "    print(\" Shape of Testing DF\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to know shape of the training and testing data\n",
    "show_shape(trainDF, testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an function to display the information of our train and test dataset. Function can be called multiple time in this notebook.\n",
    "def show_info(train, test):\n",
    "    \"\"\" \n",
    "    display the Information of train and test DF \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Information of Training DF\"+ \"-\"*10)\n",
    "    print(train.info())\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"Information of Testing DF\"+ \"-\"*10)\n",
    "    print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_info(trainDF, testDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove Object type of feature from train and test datasets.\n",
    "\n",
    "Here we have some columns to remove from dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removedFeatures = ['Name', 'Ticket', 'Cabin']\n",
    "\n",
    "trainDF = trainDF.drop(removedFeatures, axis=1) # remove from train DF\n",
    "testDF = testDF.drop(removedFeatures, axis=1) # remove from test DF\n",
    "\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age Feature\n",
    "\n",
    "trainDF['Age'] = trainDF['Age'].fillna(trainDF['Age'].mean()) # fill for train DF\n",
    "testDF['Age'] = testDF['Age'].fillna(testDF['Age'].mean()) # fill for test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['Embarked'].value_counts() # Group Wise count records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill to Embarked column NA with S\n",
    " \n",
    "trainDF['Embarked'] = trainDF['Embarked'].fillna('S') # for train DF only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show info of train and test data set by calling function\n",
    "\n",
    "show_info(trainDF, testDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show servived graph\n",
    " \n",
    "\n",
    "# Plot Counts for Each survived groupby counts\n",
    "fig = px.bar(trainDF.Survived.value_counts())\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "# Plot Counts for Each survived groupby counts\n",
    "fig = px.bar(trainDF.groupby(['Survived']).count())\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(trainDF, x='Survived', y='Pclass', color='Pclass');\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "sns.catplot(x=\"Pclass\", col=\"Survived\", data=trainDF, kind=\"count\");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(trainDF, x='Pclass', y= 'Survived', color='Pclass', )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Pclass wise survived graph \n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.barplot(x= 'Pclass', y='Survived', data=trainDF)\n",
    "plt.title(\"Pclass wise survived \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender wise Survived graph\n",
    "\n",
    "fig = px.bar(trainDF, x='Sex', y='Survived', color='Sex')\n",
    "fig.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parch and Survived Bar graph\n",
    " \n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.barplot(x = 'Parch', y= 'Survived', data= trainDF)\n",
    "plt.title(\"Parch and Survived Graph\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked and Survived bar Graph\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.barplot(x= 'Embarked', y = 'Survived', data= trainDF)\n",
    "plt.title(\"Embarked and Survived Graph\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.distplot(trainDF.Fare)\n",
    "plt.title('Distribution of Fares')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap show\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(trainDF.corr(), cmap='Greens', linewidths=1, annot=True, fmt='.1f')\n",
    "\n",
    "fig=plt.gcf()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the info\n",
    "show_info(trainDF, testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill na with median for Fare feature\n",
    "\n",
    "testDF[\"Fare\"] = testDF[\"Fare\"].fillna(testDF[\"Fare\"].mean()) # for test DF only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sex object values to numeric male=1 and female=0, for both train and test DF\n",
    "\n",
    "trainDF['Sex'] = trainDF['Sex'].replace({'male': 0, 'female': 1})\n",
    "testDF['Sex'] = testDF['Sex'].replace({'male': 0, 'female': 1})\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count values for Embarked\n",
    "print(testDF['Embarked'].value_counts())\n",
    "print(trainDF['Embarked'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Now, Replace with alphabets to Numbers, for both train and test DF\n",
    "\n",
    "trainDF['Embarked'] = trainDF['Embarked'].replace({'C': 1, 'S':2, 'Q': 3})\n",
    "testDF['Embarked'] = testDF['Embarked'].replace({'C': 1, 'S': 2, 'Q': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainDF.head())\n",
    "print(testDF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# 4. Model Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Prediction value\n",
    "\n",
    "X_train = trainDF.drop(['PassengerId', 'Survived'], axis=1)\n",
    "y_train = trainDF['Survived']\n",
    "X_test = testDF.drop(['PassengerId'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To predict our model\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show prediction\n",
    "\n",
    "accu = model.score(X_train, y_train) # model accuracy\n",
    "print( \"Model Prediction Score\", (accu * 100).round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\n",
    "    'PassengerId' : testDF['PassengerId'],\n",
    "    'Survived' : pred\n",
    "}\n",
    "\n",
    "new_submission = pd.DataFrame(dict, )\n",
    "new_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Submission File\n",
    "# new_submission.to_csv('./my_new_submission.csv', index=False)\n",
    "# print(\"Submission Successfully Saved...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \n",
    "Other Machine learning scores calculating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import other Models Classes\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_wise_predict(models):\n",
    "    \"\"\" \n",
    "    Model Predictions\n",
    "    \n",
    "    \"\"\"\n",
    "    ans_score = []\n",
    "    for mdl, filename in models:\n",
    "        m = mdl\n",
    "        m.fit(X_train, y_train)\n",
    "        pred = m.predict(X_test)\n",
    "        m_accuracy = m.score(X_train, y_train)\n",
    "        ans_score.append((m_accuracy*100).round(2))\n",
    "        \n",
    "        dict = {\n",
    "            'PassengerId' : testDF['PassengerId'],\n",
    "            'Survived' : pred\n",
    "        }\n",
    "        new_submission = pd.DataFrame(dict, )\n",
    "        \n",
    "        \n",
    "        new_submission.to_csv(filename, index=False)\n",
    "        \n",
    "        \n",
    "    return ans_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Using DecisionTreeClassifier Model\n",
    "\n",
    "#  make list of Models\n",
    "models = [\n",
    "    (RandomForestClassifier(n_estimators=300, max_depth=20, random_state=5), 'DTC_submission.csv'),\n",
    "    (RandomForestClassifier(), 'RFC_submission.csv'),\n",
    "    (LogisticRegression(), 'LR_submission.csv'),\n",
    "    (LinearSVC(), 'SVC_submission.csv'),\n",
    "    (GaussianNB(), 'GNB_submission.csv'),\n",
    "    (SGDClassifier(), 'SGD_submission.csv'),\n",
    "    (KNeighborsClassifier(), 'KNC_submission.csv')\n",
    "]\n",
    "\n",
    "data = model_wise_predict(models)\n",
    "print(\"scores are\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_model_name = [\n",
    "    'DecisionTreeClassifier',\n",
    "    'RandomForestClassifier',\n",
    "    'LogisticRegression', \n",
    "    'LinearSVC',\n",
    "    'GaussianNB',\n",
    "    'SGDClassifier', \n",
    "    'KNeighborsClassifier'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize Model\n",
    "# TEST\n",
    "\n",
    "# HYPER TUNNING -------------------------------------------------------------- Start\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "rfc_model = RandomForestClassifier(random_state=45)\n",
    "\n",
    "rfc_params_grid = {\n",
    "    'n_estimators' : np.arange(100, 1000, 100),\n",
    "    'max_depth' : [ 4, 5, 6, 7, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "# params = {'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001],\n",
    "#           'n_estimators':[100,250,500,750,1000,1250,1500,1750],\n",
    "#           'max_depth': np.random.randint(1, (len(train.columns)*.85),20),\n",
    "#           'max_features': np.random.randint(1, len(train.columns),20),\n",
    "#           'min_samples_split':[2,4,6,8,10,20,40,60,100], \n",
    "#           'min_samples_leaf':[1,3,5,7,9],\n",
    "#           'criterion': [\"gini\", \"entropy\"]}\n",
    "\n",
    "gscv_random_classifier = GridSearchCV(estimator=rfc_model, param_grid=rfc_params_grid, cv=5)\n",
    "\n",
    "gscv_random_classifier.fit(X_train, y_train)\n",
    "\n",
    "pred = gscv_random_classifier.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(gscv_random_classifier.best_estimator_)\n",
    "print(gscv_random_classifier.best_score_)\n",
    "print(gscv_random_classifier.best_score_)\n",
    "\n",
    "# HYPER TUNNING -------------------------------------------------------------- END\n",
    "\n",
    "\n",
    "# Submission FILE EXPORTING  -------------------------------------------------------------- Start\n",
    "\n",
    "# m = RandomForestClassifier(n_estimators=1000, max_depth=1000, random_state=1000)\n",
    "# m.fit(X_train, y_train)\n",
    "# pred = m.predict(X_test)\n",
    "\n",
    "\n",
    "# dict = {\n",
    "#     'PassengerId' : testDF['PassengerId'],\n",
    "#     'Survived' : pred\n",
    "# }\n",
    "\n",
    "# new_submission = pd.DataFrame(dict, )\n",
    "# new_submission.to_csv('Random-Forest-Class-Grid-Search-CV.csv', index=False)\n",
    "\n",
    "# Submission FILE EXPORTING  -------------------------------------------------------------- END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "97.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelDF = pd.DataFrame({\"Model_Name\" : list_model_name, \"Pred_Score\": data})\n",
    "modelDF.sort_values(by='Pred_Score', ascending=False)\n",
    "modelDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
